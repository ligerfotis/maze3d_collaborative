game:
    test_model: False # no training
    checkpoint_name: "sac_20201216_17-25-51"
    load_checkpoint: False
    second_human: False


SAC:
  discrete: True
  layer1_size: 256  # number of variables in hidden layer
  layer2_size: 256
  batch_size: 256
  gamma: 0.99  # discount factor
  tau: 0.005
  alpha: 0.0003
  beta: 0.0003
  target_entropy_ratio: 0.4

#  use_custom_reward: True

Experiment:
  max_episodes: 5  # max training episodes
  max_timesteps: 10  # max timesteps in one episode
  buffer_memory_size: 1000000

  action_duration: 0.02 # sec
  start_training_step_on_episode: 5
  learn_every_n_episodes: 5
  update_cycles: 0
  reward_scale: 2
  # solved_reward = 230  # stop training if avg_reward > solved_reward
  log_interval: 5  # print avg reward in the interval
  #chkpt_dir = "tmp/sac_fotis"


# Commnets: Right Down
